---
title: "HW4"
author: "Ben Hertzberg"
date: "2022-11-03"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
titanic <- read.csv('./data/titanic.csv')
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(discrim)
library(poissonreg)
library(corrr)
library(klaR)
tidymodels_prefer()
```


```{r}
titanic$survived <- as.factor(titanic$survived)
titanic$pclass <- as.factor(titanic$pclass)
```


### Question 1

```{r}
set.seed(619)

ttnc_split <- initial_split(titanic, prop = 0.80, strata = survived)
ttnc_train <- training(ttnc_split)
ttnc_test <- testing(ttnc_split)

```

```{r}
dim(ttnc_train)
dim(ttnc_test)
```
712 training observations, 179 testing observations, which is about 80% training and 20% testing.

```{r}
ttnc_rec <- recipe(survived ~ pclass + sex + age + sib_sp + parch + fare, data = ttnc_train) %>%

  step_impute_linear() %>%
  step_dummy(all_nominal_predictors()) %>%  
  step_normalize(all_numeric_predictors()) %>%
  step_interact(terms = ~starts_with("sex"):fare) %>%
  step_interact(terms = ~age:fare)
```

### Question 2

```{r}
ttnc_folds <- vfold_cv(ttnc_train, v = 10)
ttnc_folds
```


### Question 3

In your own words, explain what we are doing in Question 2. What is *k*-fold cross-validation? Why should we use it, rather than simply fitting and testing models on the entire training set? If we **did** use the entire training set, what resampling method would that be?

In Q2, we randomly assigned observations from the training data into 10 roughly equal subsets to be used in k-fold cross-validation. K-fold CV offers a way to check how well our model is doing before applying it on the testing data. This is done by training a model on every fold except one, and then effectively testing on that last fold. K total models are trained, each one using a different fold to test on and training on all the others. This offers the benefit of checking how a model works on data it was not trained on before actually applying it to the test data. If we fit and train models on the entire training set right away, we have to use the testing data to do this check, and then we can't make adjustments to the model without risking data leakage.

### Question 4

Set up workflows for 3 models:

1. A logistic regression with the `glm` engine;
2. A linear discriminant analysis with the `MASS` engine;
3. A quadratic discriminant analysis with the `MASS` engine.

```{r}
log_reg <- logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')

log_wkflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(ttnc_rec)

lda_mod <- discrim_linear() %>% 
  set_engine('MASS') %>% 
  set_mode('classification')

lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(ttnc_rec)
```


How many models, total, across all folds, will you be fitting to the data? To answer, think about how many folds there are, and how many models you'll fit to each fold.

### Question 5

Fit each of the models created in Question 4 to the folded data.

**IMPORTANT:** *Some models may take a while to run – anywhere from 3 to 10 minutes. You should NOT re-run these models each time you knit. Instead, run them once, using an R script, and store your results; look into the use of [loading and saving](https://www.r-bloggers.com/2017/04/load-save-and-rda-files/). You should still include the code to run them when you knit, but set `eval = FALSE` in the code chunks.*

### Question 6

Use `collect_metrics()` to print the mean and standard errors of the performance metric *accuracy* across all folds for each of the four models.

Decide which of the 3 fitted models has performed the best. Explain why. *(Note: You should consider both the mean accuracy and its standard error.)*

### Question 7

Now that you’ve chosen a model, fit your chosen model to the entire training dataset (not to the folds).

### Question 8

Finally, with your fitted model, use `predict()`, `bind_cols()`, and `accuracy()` to assess your model’s performance on the testing data!

Compare your model’s testing accuracy to its average accuracy across folds. Describe what you see.
